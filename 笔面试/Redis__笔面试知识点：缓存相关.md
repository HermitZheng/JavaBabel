# Redis__笔面试知识点：缓存相关

## 缓存相关知识

### 缓存出现的问题

#### 缓存雪崩

Redis不可能把所有的数据都缓存起来(**内存昂贵且有限**)，所以Redis需要对数据设置**过期时间**，并采用的是**惰性删除+定期删除**两种策略对过期键删除。如果缓存数据**设置的过期时间是相同**的，并且Redis恰好将这部分数据全部删光了。这就会导致在这段时间内，这些缓存**同时失效**，全部请求到数据库中，即缓存雪崩。

一般有两种情况会引起缓存雪崩：

- **Redis挂掉了**，请求全部走数据库。
- 对缓存数据设置**相同的过期时间**，导致某段时间内缓存全部失效，请求全部走数据库。

**解决方案**：

对于**“设置了相同的过期时间”**这种情况，非常好解决：

- 解决方法：在缓存的时候给过期时间加上一个**随机值**，这样就会大幅度的**减少缓存在同一时间过期**。

对于**“Redis挂掉了”**这种情况，我们可以有以下的思路：

- 事发前：实现Redis的**高可用**(主从架构+Sentinel 或者Redis Cluster)，尽量避免Redis挂掉这种情况发生。
- 事发中：万一Redis真的挂了，我们可以设置**本地缓存(ehcache)+限流(hystrix)**，尽量避免我们的数据库被干掉(起码能保证我们的服务还是能正常工作的)
- 事发后：Redis**持久化**，重启后自动从磁盘上加载数据，**快速恢复缓存数据**。



#### 缓存穿透

缓存穿透是指查询一个一定**不存在的数据**。由于缓存不命中，并且出于容错考虑，如果从**数据库查不到数据则不写入缓存**，这将导致这个不存在的数据**每次请求都要到数据库去查询**，失去了缓存的意义。即缓存穿透：

- 请求的数据在缓存**大量不命中**，导致请求走数据库。

**解决方案：**

- 由于请求的**参数是不合法的**(每次都请求不存在的参数)，于是我们可以使用**布隆过滤器**(BloomFilter)或者压缩filter**提前拦截**，不合法就不让这个请求到数据库层。也可以进行鉴权、参数范围的设定等，例如分页大小做一个限制（防止Integer.MAX_VALUE大小的页请求）

- 当我们从数据库找不到的时候，我们也将这个**空对象设置到缓存里边去**。下次再请求的时候，就可以从缓存里边获取了。

- - 这种情况我们一般会将空对象设置一个**较短的过期时间**。

##### 布隆过滤器

我们常见的将业务字段拼接之后md5，放在一个集合中。 md5生成一个固定长度的128bit的串。 如果我们用bitmap来表示，则需要

```
2**128 = 340282366920938463463374607431768211456 bit
```

判断一个值在不在，就变成在这个**bitmap**中判断所在**位**是否为1。 但是我们全世界的机器存储空间也无法存储下载。 因此我们只能分配有限的空间来存储。位图不是特殊的数据结构，它的内容其实就是**普通的字符串**，也就是 **byte 数组**。我们可以使用普通的 get/set 直接获取和设置整个位图的内容，也可以使用位图操作 `getbit/setbit `等将 byte 数组看成「位数组」来处理。这个类型不仅仅可以用来让我们改二进制改字符串值，最经典的就是**用户连续签到**。

key 可以设置为 前缀:用户id:年月

`setbit sign:123:1909 0 1`

```python
import crc32

def BloomFilter(sample, size, hash_size=1):
    # 构造一个hash函数，将输入数据散列到size一个位置上
    hash = lambda x:crc32(str(x).encode())%size
    collision, s = 0, set()
    for i in range(sample):
        k = set()
        for j in range(hash_size):
            k.add(hash(i+j*size/hash_size))
        # 只有所有散列结果k都在s中，才认为i重复
        if not k - s:
            collision += 1
            continue
        # 将散列结果k更新到集合s中
        s |= k
    return collision
```

当使用一个Hash函数时，很容易发生冲突，当**增加hash方法的个数**能够有效的**降低碰撞机率**。但是增加了hash方法之后，会**降低空间的使用效率**。一个值会被多个Hash算法算出多个结果存起来（数组对应下标位置的值置为一）；同时当有查询请求时，也会被算出多个值来进行对比，只有所有位置都相对应，才能通过过滤。当集合占用总体空间达到25%的时候， 增加hash 的效果已经不明显。BloomFilter 需要一个大的bitmap来存储。

**算法优点：**	

- **数据空间小，不用存储数据本身。**

**算法本身缺点：**

- 元素可以添加到集合中，但**不能被删除**。
- 匹配结果只能是“绝对不在集合中”，并**不能保证匹配成功的值已经在集合中（Hash碰撞）**。
- 当**集合快满**时，即接近预估最大容量时，**误报的概率会变大**。
- **数据占用空间放大**。一般来说，对于1％的误报概率，每个元素少于10比特，与集合中的元素的大小或数量无关。  查询过程变慢，hash函数增多，导致每次匹配过程，需要查找多个位（hash个数）来确认是否存在。

对于BloomFilter的优点来说，缺点都可以忽略。毕竟只需要kN的存储空间就能存储N个元素。空间效率十分优秀。



#### 缓存击穿

缓存击穿是**指一个Key非常热点，在不停的扛着大并发**，大并发集中对这一个点进行访问，**当这个Key在失效的瞬间，持续的大并发就穿破缓存**，直接请求数据库，就像在一个完好无损的桶上凿开了一个洞。

**解决方案**：

- 设置热点缓存永不过期
- 加上互斥锁

**互斥锁**

```java
    static Lock lock = new ReentrantLock();

    public static String getDate(String key) throws InterruptedException {
        // 尝试从缓存中拿
        String result = getDataByKV(key);
        // 缓存空了
        if (!result.equals("")) {
            // 能获取到锁
            if (lock.tryLock()) {
                // 从数据库中拿到最新的数据
                result = getDataByDB(key);
                // 更新到缓存;
                if (!result.equals("")) {
                    setDataToKV(key, result);
                }
                lock.unlock();
            } else {
                // 拿不到锁的话，过一会再试
                // 如果其他线程已经刷新过缓存，那就可以直接拿到了
                Thread.sleep(100L);
                result = getDate(key);
            }
        }
        return result;
    }
```



#### 双写一致

一般我们对**读操作**的时候有这么一个**固定的套路**：

- 如果我们的数据在缓存里边有，那么就直接取缓存的。
- 如果缓存里没有我们想要的数据，我们会先去查询数据库，然后**将数据库查出来的数据写到缓存中**。
- 最后将数据返回给请求

如果仅仅查询的话，缓存的数据和数据库的数据是没问题的。但是，当我们要**更新**时候呢？各种情况很可能就**造成数据库和缓存的数据不一致**了。

- 这里不一致指的是：**数据库的数据跟缓存的数据不一致**

从理论上说，只要我们设置了**键的过期时间**，我们就能保证缓存和数据库的数据**最终是一致**的。因为只要缓存数据过期了，就会被删除。随后读的时候，因为缓存里没有，就可以查数据库的数据，然后将数据库查出来的数据写入到缓存中。除了设置过期时间，我们还需要做更多的措施来**尽量避免**数据库与缓存处于不一致的情况发生。

一般来说，执行**更新操作**时，我们会有两种选择：

- **先操作数据库，再操作缓存**
- **先操作缓存，再操作数据库**

首先，要明确的是，无论我们选择哪个，我们都希望这**两个操作要么同时成功，要么同时失败**。所以，这会演变成一个**分布式事务**的问题。

所以，**如果原子性被破坏了**，可能会有以下的情况：

- **操作数据库成功了，操作缓存失败了**。
- **操作缓存成功了，操作数据库失败了**。

> 如果第一步已经失败了，我们直接返回Exception出去就好了，第二步根本不会执行。

高并发环境下，无论是先操作数据库还是后操作数据库而言，如果加上更新缓存，那就**更加容易**导致数据库与缓存数据不一致问题。所以建议直接**删除缓存**！

具体操作见下文



### 缓存读写模式/更新策略

**下面介绍到的三种模式各有优劣，不存在最佳模式，根据具体的业务场景选择适合自己的缓存读写模式。**

#### Cache Aside Pattern（旁路缓存模式）

1. 写：更新 DB，然后直接删除 cache 。
2. 读：从 cache 中读取数据，读取到就直接返回；读取不到的话，就从 DB 中取数据返回，然后**再把数据放到 cache 中**。

Cache Aside Pattern 中服务端需要同时维系 DB 和 cache，并且是**以 DB 的结果为准**。另外，Cache Aside Pattern **有首次请求数据一定不在 cache** 的问题，对于热点数据可以**提前放入缓存**中。

**Cache Aside Pattern 是我们平时使用比较多的一个缓存读写模式，比较适合读请求比较多的场景。**

**删除缓存失败的解决思路**：

- 将需要删除的key发送到**消息队列**中
- 自己消费消息，获得需要删除的key
- **不断重试删除操作，直到成功**



#### Read/Write Through Pattern（读写穿透）

Read/Write Through 套路是：服务端**把 cache 视为主要数据存储**，从中读取数据并将数据写入其中。cache 服务负责**将此数据读取和写入 DB**，从而减轻了应用程序的职责。

1. 写（Write Through）：先查 cache，cache 中不存在，直接更新 DB。 cache 中存在，则先更新 cache，然后 cache 服务自己更新 DB（**同步更新 cache 和 DB**）。
2. 读(Read Through)： 从 cache 中读取数据，读取到就直接返回 。读取不到的话，先从 DB 加载，写入到 cache 后返回响应。

Read-Through Pattern 实际只是在 Cache-Aside Pattern 之上进行了封装。在 Cache-Aside Pattern 下，发生读请求的时候，如果 **cache 中不存在对应的数据**，是由**客户端自己负责把数据写入 cache**，而 Read Through Pattern 则是 **cache 服务自己来写入缓存**的，这对客户端是透明的。

和 Cache Aside Pattern 一样， Read-Through Pattern 也有首次请求数据一定不再 cache 的问题，对于热点数据可以提前放入缓存中。



#### Write Behind Pattern（异步缓存写入）

Write Behind Pattern 和 Read/Write Through Pattern 很相似，两者都是**由 cache 服务来负责 cache 和 DB 的读写**。

但是，两个又有很大的不同：**Read/Write Through 是同步更新 cache 和 DB，而 Write Behind Caching 则是只更新缓存，不直接更新 DB，而是改为异步批量的方式来更新 DB。**

**Write Behind Pattern 下 DB 的写性能非常高，尤其适合一些数据经常变化的业务场景比如说一篇文章的点赞数量、阅读数量。** 往常一篇文章被点赞 500 次的话，需要重复修改 500 次 DB，但是在 Write Behind Pattern 下可能只需要修改一次 DB 就可以了。

但是，这种模式同样也给 DB 和 Cache 一致性带来了新的考验，很多时候如果数据还没异步更新到 DB 的话，Cache 服务宕机就 gg 了。